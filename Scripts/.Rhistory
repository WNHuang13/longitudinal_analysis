X_1996 ~ a2*X_1994
Y_1994 ~ b1*Y_1992
Y_1996 ~ b2*Y_1994
# cross-lagged paths
X_1994 ~ c1*Y_1992
X_1996 ~ c2*Y_1994
Y_1994 ~ d1*X_1992
Y_1996 ~ d2*X_1994
# correlations
X_1992 ~~ Y_1992
X_1994 ~~ Y_1994
X_1996 ~~ Y_1996
'
df_wide <- df_wide %>%
mutate(across(starts_with("X_"), ~ map_dbl(., ~ mean(unlist(.), na.rm = TRUE)))) %>%
mutate(across(starts_with("income_"), ~ map_dbl(., ~ mean(unlist(.), na.rm = TRUE))))
df_wide <- df_wide %>%
select(id,
X_1992, X_1994, X_1996,
income_1992, income_1994, income_1996)
model_clpm <- '
# autoregressive (stability) paths
X_1994 ~ a1*X_1992
X_1996 ~ a2*X_1994
income_1994 ~ b1*income_1992
income_1996 ~ b2*income_1994
# cross-lagged effects
X_1994 ~ c1*income_1992
X_1996 ~ c2*income_1994
income_1994 ~ d1*X_1992
income_1996 ~ d2*X_1994
# within-wave correlations
X_1992 ~~ income_1992
X_1994 ~~ income_1994
X_1996 ~~ income_1996
'
# --- 5. Fit model with FIML ----------------------------------------
fit_clpm <- sem(model_clpm, data = df_wide, missing = "fiml")
# --- 6. Inspect results ---------------------------------------------
summary(fit_clpm, fit.measures = TRUE, standardized = TRUE)
params <- parameterEstimates(fit_clpm, standardized = TRUE) %>%
filter(op == "~")
ggplot(params, aes(x = rhs, y = std.all, fill = lhs)) +
geom_col(position = "dodge") +
coord_flip() +
theme_minimal(base_size = 13) +
labs(
title = "Cross-Lagged Panel Model (SSW ↔ Income)",
subtitle = "Standardized regression coefficients",
x = "Predictor (previous wave)",
y = "Standardized β"
)
# --- 9. Optional: model fit indices ---------------------------------
fitMeasures(fit_clpm, c("cfi", "tli", "rmsea", "srmr"))
library(semPlot)
semPaths(
fit_clpm,
whatLabels = "std",     # 显示标准化系数
layout = "circle2",     # 节点布局方式（可选 spring / tree / circle）
edge.label.cex = 0.8,   # 文字大小
nCharNodes = 8,         # 节点名称长度
residuals = FALSE,      # 是否显示误差项
asize = 1.5,            # 箭头粗细
fade = FALSE,           # 不要淡化
title = FALSE,
edge.color = "black"
)
params <- parameterEstimates(fit_clpm, standardized = TRUE) %>%
filter(op == "~") %>%
mutate(from = rhs, to = lhs)
ggplot(params, aes(x = from, y = to, fill = std.all)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
theme_minimal(base_size = 12) +
labs(
title = "Cross-Lagged Effects (Standardized)",
x = "Predictor (previous wave)",
y = "Outcome (next wave)",
fill = "β"
)
params <- parameterEstimates(fit_clpm, standardized = TRUE) %>%
filter(op == "~") %>%
mutate(type = case_when(
grepl("X_", lhs) & grepl("X_", rhs) ~ "Autoregressive (SSW)",
grepl("income_", lhs) & grepl("income_", rhs) ~ "Autoregressive (Income)",
grepl("X_", lhs) & grepl("income_", rhs) ~ "Income→SSW",
grepl("income_", lhs) & grepl("X_", rhs) ~ "SSW→Income"
))
ggplot(params, aes(x=type, y=std.all, fill=type)) +
geom_bar(stat="identity", position="dodge") +
theme_minimal(base_size = 13) +
labs(title="Path Coefficient Comparison", y="Standardized β", x="Path Type") +
coord_flip()
library(tidyverse)
library(survival)
library(survminer)
df_surv <- df_long %>%
group_by(id) %>%
summarise(
time = max(year, na.rm = TRUE) - min(year, na.rm = TRUE),
ssw_mean = mean(ssw, na.rm = TRUE),
income_mean = mean(income, na.rm = TRUE),
event = max(event, na.rm = TRUE)
) %>%
ungroup()
name(SSWEALTH)
NAMES(SSWEALTH)
names(SSWEALTH)
library(tidyverse)
library(survival)
library(survminer)
df_long_raw <- SSWEALTH %>%
select(HHID, PN, matches("^R\\d+(SSWRXA|CLAIMED)$")) %>%
pivot_longer(
cols = -c(HHID, PN),
names_to   = c("wave","var"),
names_pattern = "^R(\\d+)(SSWRXA|CLAIMED)$",
values_to  = "value"
) %>%
mutate(
wave = as.integer(wave),
year = 1990 + 2*wave,                 # R1=1992, R2=1994, ..., R15=2020
id   = paste0(HHID, "_", PN)
) %>%
select(id, year, wave, var, value) %>%
pivot_wider(names_from = var, values_from = value)
df_long <- df_long_raw %>%
mutate(
SSWRXA   = suppressWarnings(as.numeric(SSWRXA)),
CLAIMED  = as.integer(CLAIMED),
ssw      = SSWRXA / 1000
) %>%
arrange(id, year)
df_surv <- df_long %>%
group_by(id) %>%
summarise(
start_year = suppressWarnings(min(year[!is.na(ssw) | !is.na(CLAIMED)], na.rm = TRUE)),
claim_year = if (any(CLAIMED == 1, na.rm = TRUE)) min(year[CLAIMED == 1], na.rm = TRUE) else NA_real_,
end_year   = ifelse(!is.na(claim_year), claim_year, suppressWarnings(max(year[!is.na(ssw) | !is.na(CLAIMED)], na.rm = TRUE))),
# Baseline covariate: ssw at or closest after start_year
ssw_base   = {
yy <- year[order(year)]
vv <- ssw[order(year)]
idx <- which.min(abs(yy - start_year))
if (length(idx) == 1) vv[idx] else NA_real_
},
# Alternative covariate: average ssw across follow-up
ssw_mean   = mean(ssw, na.rm = TRUE),
.groups = "drop_last"
) %>%
ungroup() %>%
mutate(
time  = pmax(end_year - start_year, 0),
event = ifelse(!is.na(claim_year), 1L, 0L)
) %>%
# Keep sensible records only
filter(is.finite(time), time >= 0)
# -------------------- 3. Kaplan–Meier estimation --------------------
surv_obj <- Surv(time = df_surv$time, event = df_surv$event)
fit_km <- survfit(surv_obj ~ 1)
print(summary(fit_km))
p_km <- ggsurvplot(
fit_km,
conf.int = TRUE,
xlab = "Years since first observation",
ylab = "Survival probability (no claiming yet)",
ggtheme = theme_minimal(base_size = 13),
title = "Time to First Social Security Claiming (Respondents)"
)
install.packages("survminer")
install.packages("survminer")
library(survival)
p_km <- ggsurvplot(
fit_km,
conf.int = TRUE,
xlab = "Years since first observation",
ylab = "Survival probability (no claiming yet)",
ggtheme = theme_minimal(base_size = 13),
title = "Time to First Social Security Claiming (Respondents)"
)
install.packages("survminer")
install.packages("survminer")
install.packages("survminer")
p_km <- ggsurvplot(
fit_km,
conf.int = TRUE,
xlab = "Years since first observation",
ylab = "Survival probability (no claiming yet)",
ggtheme = theme_minimal(base_size = 13),
title = "Time to First Social Security Claiming (Respondents)"
)
library(survival)
# Plot KM curve
# 使用 survival 包直接计算生存函数
fit_km <- survfit(Surv(time, event) ~ 1, data = df_surv)
km_df <- data.frame(
time = fit_km$time,
surv = fit_km$surv,
lower = fit_km$lower,
upper = fit_km$upper
)
ggplot(km_df, aes(x = time, y = surv)) +
geom_line(color = "steelblue", size = 1.2) +
geom_ribbon(aes(ymin = lower, ymax = upper), fill = "lightblue", alpha = 0.3) +
theme_minimal(base_size = 13) +
labs(
title = "Time to First Social Security Claiming (Respondents)",
subtitle = "Kaplan–Meier survival curve",
x = "Years since first observation",
y = "Survival probability (no claiming yet)"
)
library(ggplot2)
ggplot(km_df, aes(x = time, y = surv)) +
geom_line(color = "steelblue", size = 1.2) +
geom_ribbon(aes(ymin = lower, ymax = upper), fill = "lightblue", alpha = 0.3) +
theme_minimal(base_size = 13) +
labs(
title = "Time to First Social Security Claiming (Respondents)",
subtitle = "Kaplan–Meier survival curve",
x = "Years since first observation",
y = "Survival probability (no claiming yet)"
)
# -------------------- 4. Cox proportional hazards -------------------
# Use baseline SSW (or switch to ssw_mean)
fit_cox <- coxph(Surv(time, event) ~ ssw_base, data = df_surv)
print(summary(fit_cox))
# Hazard ratios plot
cox_coef <- tidy(fit_cox, exponentiate = TRUE, conf.int = TRUE)
p_hr <- ggplot(cox_coef, aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
geom_pointrange() +
geom_hline(yintercept = 1, linetype = "dashed") +
coord_flip() +
theme_minimal(base_size = 13) +
labs(
title = "Cox Model: Hazard Ratios for Claiming",
x = "Predictor",
y = "Hazard Ratio (exp(β))"
)
library(broom)
cox_coef <- tidy(fit_cox, exponentiate = TRUE, conf.int = TRUE)
p_hr <- ggplot(cox_coef, aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
geom_pointrange() +
geom_hline(yintercept = 1, linetype = "dashed") +
coord_flip() +
theme_minimal(base_size = 13) +
labs(
title = "Cox Model: Hazard Ratios for Claiming",
x = "Predictor",
y = "Hazard Ratio (exp(β))"
)
p_hr <- ggplot(cox_coef, aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
geom_pointrange() +
geom_hline(yintercept = 1, linetype = "dashed") +
coord_flip() +
theme_minimal(base_size = 13) +
labs(
title = "Cox Model: Hazard Ratios for Claiming",
x = "Predictor",
y = "Hazard Ratio (exp(β))"
)
p_hr
library(haven)
SSWEALTH <- read_sav("C:/Users/whua616/OneDrive - The University of Auckland/Codes/Longitudinal_Modeling_R/Data/SSWEALTH.sav")
View(SSWEALTH)
library(readr)
SSW_long <- read_csv("C:/Users/whua616/OneDrive - The University of Auckland/Codes/Longitudinal_Modeling_R/Data/SSW_long.csv")
View(SSW_long)
library(readr)
SSW_wide <- read_csv("C:/Users/whua616/OneDrive - The University of Auckland/Codes/Longitudinal_Modeling_R/Data/SSW_wide.csv")
View(SSW_wide)
library(tidyverse)
library(lavaan)
library(ggplot2)
library(readr)
df_long <- read_csv("C:/Users/whua616/OneDrive - The University of Auckland/Codes/Longitudinal_Modeling_R/Data/df_long.csv")
View(df_long)
library(readr)
df_wide <- read_csv("C:/Users/whua616/OneDrive - The University of Auckland/Codes/Longitudinal_Modeling_R/Data/df_wide.csv")
View(df_wide)
glimpse(df_wide)
ssw_vars <- paste0("ssw_", seq(1992, 2020, 2))
View(df_wide)
randhrs1992_2022 <- read_sav("C:/Users/whua616/OneDrive - The University of Auckland/Codes/Longitudinal_Modeling_R/Data/randhrs1992_2022.sav")
hrs_data_raw <- read_sav(
"C:/Users/whua616/OneDrive - The University of Auckland/Codes/Longitudinal_Modeling_R/Data/randhrs1992_2022.sav",
col_select = all_vars_to_select # 只读取这个列表中的列
)
install.packages("foreign")
library(foreign)
hrs_data_raw <- foreign::read.spss(
"C:/Users/whua616/OneDrive - The University of Auckland/Codes/Longitudinal_Modeling_R/Data/randhrs1992_2022.sav",
to.data.frame = TRUE)
install.packages("rio")
library(rio)
install.packages("data.table")
library(data.table)
# !!! 请将此路径替换为您文件的实际路径 !!!
file_path <- "C:/Users/whua616/OneDrive - The University of Auckland/Codes/Longitudinal_Modeling_R/Data/randhrs1992_2022.sav"
# 此处定义您要使用的波次编号，从第 5 波次 (2000年) 开始到第 15 波次 (2020年)
waves <- 5:15
# 核心 ID 变量
id_vars <- c("hhid", "pn")
time_invariant_vars <- c(
"rabyear",   # 出生年份
"raedu",     # 教育水平（基线）
"ragender"   # 性别
)
time_varying_vars_stem <- c(
"srh",     # 自评健康 (Self-Rated Health) - D.V.
"cog",     # 认知总分 (Cognition) - D.V.
"iadl",    # IADL 限制 (IADL Limitations) - D.V.
"mart",    # 婚姻状态 (Marriage Status) - I.V.
"antot",   # 家庭净资产 (Net Worth) - I.V.
"inltot"   # 家庭总收入 (Total Income) - I.V.
)
wave_vars_list <- unlist(lapply(time_varying_vars_stem, function(v) {
return(paste0("r", waves, v))
}))
# 完整的筛选变量列表
all_vars_to_select <- c(id_vars, time_invariant_vars, wave_vars_list)
cat("正在使用 rio::import 高效读取大型 .sav 文件（data.table 格式）。请耐心等待...\n")
hrs_data_raw <- rio::import(
file_path,
setclass = "data.table" # 强制设置为 data.table 格式以提高效率
)
View(hrs_data_raw)
hrs_data_wide <- hrs_data_raw %>%
select(all_of(all_vars_to_select)) %>%
mutate(across(c(all_of(time_invariant_vars), all_of(wave_vars_list)), as.numeric)) %>%
mutate(
education = raedu,
gender = ragender
) %>%
filter(if_any(starts_with("r"), ~ !is.na(.x)))
hrs_data_raw <- as_tibble(hrs_data_raw)
hrs_data_wide <- hrs_data_raw %>%
select(all_of(all_vars_to_select)) %>%
mutate(across(c(all_of(time_invariant_vars), all_of(wave_vars_list)), as.numeric)) %>%
mutate(
education = raedu,
gender = ragender
) %>%
filter(if_any(starts_with("r"), ~ !is.na(.x)))
colnames(hrs_data_raw)
install.packages("janitor")
library(janitor)
data_wide <- data_raw %>%
clean_names() %>%
rename(id = hhidpn)
data_wide <- hrs_data_raw %>%
clean_names() %>%
rename(id = hhidpn)
vars_id <- c("id", "gender", "race", "hispanic", "educ")
vars_wave <- c(
paste0("r", 1:16, "agey_e"),   # age
paste0("r", 1:16, "srh"),      # self-rated health
paste0("r", 1:16, "cesd"),     # depression
paste0("r", 1:16, "adl"),      # ADL count
paste0("r", 1:16, "iadl"),     # IADL count
paste0("r", 1:16, "cog")       # cognitive score
)
vars_wave <- c(
paste0("r", 1:16, "agey_e"),
paste0("r", 1:16, "srh"),
paste0("r", 1:16, "cesd"),
paste0("r", 1:16, "adl"),
paste0("r", 1:16, "iadl"),
paste0("r", 1:16, "cog")
)
data_wide <- data_wide %>%
select(all_of(vars_id), all_of(vars_wave))
data_wide <- data_wide %>%
select(all_of(vars_id), all_of(vars_wave))
View(names(data_raw))
View(names(hrs_data_raw))
View(names(hrs_data_raw))
names(hrs_data_raw)
vars_id <- c("HHIDPN")
vars_demo <- c(paste0("S", 1:16, "RACEM"),
paste0("S", 1:16, "HISPAN"),
paste0("S", 1:16, "GENDER"),
paste0("S", 1:16, "EDUC"))
vars_wave <- c(
paste0("R", 1:16, "AGEY_E"),  # 年龄
paste0("R", 1:16, "SRH"),     # 主观健康
paste0("R", 1:16, "CESD"),    # 抑郁
paste0("R", 1:16, "ADL"),     # ADL 限制
paste0("R", 1:16, "IADL"),    # IADL 限制
paste0("R", 1:16, "COG")      # 认知分数
)
data_wide <- hrs_data_raw %>%
select(all_of(vars_id), all_of(vars_demo), all_of(vars_wave))
grep("SRH", names(hrs_data_raw), value = TRUE)
grep("CESD", names(hrs_data_raw), value = TRUE)
grep("COG", names(hrs_data_raw), value = TRUE)
vars_demo <- c("S1RACEM", "S1HISPAN", "S1GENDER", "S1EDUC")
vars_cesd <- c(paste0("S", 1:16, "CESD"), paste0("R", 2:16, "CESD"))
vars_cog <- c(paste0("S", 3:16, "COG27"), paste0("R", 3:16, "COG27"))
vars_wave <- c(vars_cesd, vars_cog)
data_wide <- hrs_data_raw %>%
select(all_of(vars_id), all_of(vars_demo), all_of(vars_wave))
vars_id <- c("HHIDPN")
vars_demo <- c("S1RACEM", "S1HISPAN", "S1GENDER", "S1EDUC")
vars_cesd_candidates <- c(paste0("S", 1:16, "CESD"), paste0("R", 1:16, "CESD"))
vars_cog_candidates  <- c(paste0("S", 3:16, "COG27"), paste0("R", 3:16, "COG27"))
existing_vars <- names(hrs_data_raw)
vars_cesd <- intersect(vars_cesd_candidates, existing_vars)
vars_cog  <- intersect(vars_cog_candidates, existing_vars)
# 合并所有需要保留的列
vars_wave <- c(vars_cesd, vars_cog)
data_wide <- hrs_data_raw %>%
select(any_of(vars_id), any_of(vars_demo), any_of(vars_wave))
data_long <- data_wide %>%
pivot_longer(
cols = matches("^(s|r)[0-9]+(cesd|cog27)$"),
names_to = c("wave", "variable"),
names_pattern = "([sr][0-9]+)(cesd|cog27)",
values_to = "value"
) %>%
pivot_wider(
names_from = variable,
values_from = value
) %>%
mutate(
wave = as.numeric(gsub("[^0-9]", "", wave)),
year = 1990 + wave * 2,       # approximate mapping
id = hhidpn
)
data_long <- data_wide %>%
pivot_longer(
cols = matches("^(s|r)[0-9]+(cesd|cog27)$"),
names_to = c("wave", "variable"),
names_pattern = "([sr][0-9]+)(cesd|cog27)",
values_to = "value"
) %>%
pivot_wider(
names_from = variable,
values_from = value,
values_fn = ~ dplyr::first(na.omit(.))
) %>%
mutate(
wave = as.numeric(gsub("[^0-9]", "", wave)),
year = 1990 + wave * 2,   # approximate mapping
id = coalesce(hhidpn, HHIDPN)
)
data_wide <- data_wide %>%
rename(id = any_of(c("hhidpn", "HHIDPN")))
data_long <- data_wide %>%
pivot_longer(
cols = matches("^(s|r)[0-9]+(cesd|cog27)$"),
names_to = c("wave", "variable"),
names_pattern = "([sr][0-9]+)(cesd|cog27)",
values_to = "value"
) %>%
pivot_wider(
names_from = variable,
values_from = value,
values_fn = ~ dplyr::first(na.omit(.))
) %>%
mutate(
wave = as.numeric(gsub("[^0-9]", "", wave)),
year = 1990 + wave * 2,   # approximate mapping
id = coalesce(hhidpn, HHIDPN)
)
data_long <- data_wide %>%
pivot_longer(
cols = matches("^(s|r)[0-9]+(cesd|cog27)$"),
names_to = c("wave", "variable"),
names_pattern = "([sr][0-9]+)(cesd|cog27)",
values_to = "value"
) %>%
pivot_wider(
names_from = variable,
values_from = value,
values_fn = ~ dplyr::first(na.omit(.))
) %>%
mutate(
wave = as.numeric(gsub("[^0-9]", "", wave)),
year = 1990 + wave * 2   # approximate mapping
)
data_long <- data_long %>%
mutate(across(c(cesd, cog27), ~na_if(., 999))) %>%
mutate(across(c(cesd, cog27), ~na_if(., -1)))
names(data_long)
names(data_wide)
data_wide <- data_wide %>%
janitor::clean_names()
names(data_wide)[1:20]
data_long <- data_wide %>%
pivot_longer(
cols = matches("^(s|r)[0-9]+(cesd|cog27)$"),
names_to = c("wave", "variable"),
names_pattern = "([sr][0-9]+)(cesd|cog27)",
values_to = "value"
) %>%
pivot_wider(
names_from = variable,
values_from = value,
values_fn = ~ dplyr::first(na.omit(.))
) %>%
mutate(
wave = as.numeric(gsub("[^0-9]", "", wave)),
year = 1990 + wave * 2   # approximate mapping
)
data_long <- data_long %>% janitor::clean_names()
names (data_long)
names(data_long)
data_long <- data_long %>%
mutate(across(c(cesd, cog27), ~na_if(., 999))) %>%
mutate(across(c(cesd, cog27), ~na_if(., -1))) %>%
mutate(across(c(cesd, cog27), ~na_if(., 98))) %>%  # 有时98表示missing
mutate(across(c(cesd, cog27), ~as.numeric(.)))      # 确保是数值型
